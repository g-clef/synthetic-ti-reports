{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 experiments. \n",
    "\n",
    "Having tried the LSTM, and gotten mixed success, let's see if we can get GPT2 to run on my setup. Rather than repeat the problems with the LSTM, though, I'm going to only use the source data with source code removed. If GTP2 works well with that set, we can dial the difficultly up by running against the source-code-included version, but let's not start with the hard part first. \n",
    "\n",
    "I'm going to be doing this all following the tutorial on fastai at https://docs.fast.ai/tutorial.transformers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from fastai.text.all import *\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to the version with source code snippets removed as well as I could\n",
    "base_dir = Path(\"/home/g-clef/local_ml_data_copy/ti-reports/1655302d-a401-4d87-a223-dbb06648bb8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is stored not in a csv, like pandas wants, but in a series of text files. have to read those in by hand to make pandas dataframe\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            values.append(infile.read())\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial talks about making this tokenizer so that we can use the HuggingFace tokenizer within fastai, rather than the built-in one     \n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then split the set of entries into a training set and a validation set, using first 90% of data. We then concatenate them back together \n",
    "# again to use the fastai splits. This seems redundant, but what I'm concerned about is the text reader pulling a biased sample of reports\n",
    "# when it reads off disk (later ones last, particular vendors first, etc), so I want the train_test_split to randomly choose the \n",
    "# members of the train and valid sets, then I reformat that to use the `splits` feature in fastai\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]\n",
    "# tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with a batch size of 4, and a sequence size of 256 (gpt2 used 1024 sequence length) to get this to fit on my GPU. That will make \n",
    "# things go slower, but that's okay.\n",
    "bs,sl = 4,256\n",
    "# dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a glue function to make the response of  the huggingface model fit inside the fastai library. Huggingface models return\n",
    "# a tuple for predictions of (prediction, additional_activations). Fastai jsut wants a predition, so we need to drop the activations.\n",
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1454' class='' max='1454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1454/1454 01:22<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16033 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [2.701354503631592,14.899900436401367]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=9.120108734350652e-05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked, and looks good from a perplexity point of view (the second number in `learn.validate`, but it's worth noting that the original way was *slow*. (the `validate` method took over an hour to run). The GPU was barely used, but one core of hte CPU was maxed out. I think what's happening is the TransformerTokenizer above is doing a lot of work, and that's all happening on the CPU, so the GPU is waiting for the CPU to repeatedly re-tokenize batches before running them. \n",
    "\n",
    "The tutorial mentioned another way to tokenize the text, which is to do it all at once, and only use the tranform to decode the output tensors (the results from a huggingface model) back to readable texts. That's what the `tokenize` and lower `transformersTokenizer` method are about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.022082</td>\n",
       "      <td>1.879266</td>\n",
       "      <td>6.548698</td>\n",
       "      <td>1:09:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/fine-tuned.pth')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(\"fine-tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: at this point I ran into a lot of problems if I left the notebook running and proceeding from here. So, I ended up saving & shutting down the notebook, then re-starting and re-loading to start here. (errors like CUDA assertion errors, unusual errors about tensor sizes not matching.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(\"fine-tuned\")\n",
    "learn.model = learn.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp, max_length=100, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider\\n                                                                                              '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's weird. It looks like there's nothing there. I wonder if the training data got somehow blanked out in the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 198,  220,  220,  ...,   14, 2091,  198])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 198,  220,  220,  ...,   14, 1065,  198])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16033"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7656"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it looks like the tokenized values are all still there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([220])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, weird. It's learned nothing but spaces. I wonder why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n        Operation    TunnelSnake\\n\\n\\n          securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Formerly  unknown  rootkit used to secretly control networks of regional organizations\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   1/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        Windows rootkits, especially those operating in kernel space, are pieces of malware infamous for their near absolute power in the\\n        operating system. Usually deployed as drivers, such implants have high privileges in the system, allowing them to intercept and\\n        potentially tamper with core I/O operations conducted by the underlying OS, like reading or writing to files or processing incoming and\\n        outgoing network packets. The capability to blend into the fabric of the operating system itself, much like security products do, is the\\n\\n        quality that earns rootkits their notoriety for stealth and evasion.\\n\\n        Having said that, the successful deployment and execution of a rootkit component in Windows has become a difficult task over the\\n        years. With Microsoft’s introduction of Driver Signature Enforcement, it has become harder (though not impossible) to load and run\\n        new code in kernel space. Even then, other mechanisms such as Kernel Patch Protection (also known as PatchGuard) make it hard to\\n\\n        tamper with the system, with every change in a core system structure potentially invoking the infamous Blue Screen of Death.\\n\\n        Consequently, the number of Windows rootkits in the wild has decreased dramatically, with the bulk of those still active often being\\n        leveraged in high profile APT attacks. One such example came to our attention during an investigation last year, in which we uncovered\\n        a formerly unknown Windows rootkit and its underlying cluster of activity. We observed this rootkit and other tools by the threat actor\\n\\n        behind it being used as part of a campaign we dubbed ‘TunnelSnake’, conducted against several prominent organizations in Asia and\\n        Africa.\\n\\n        In this blog post we will focus on the following key findings that came up in our investigation:\\n\\n            A newly discovered rootkit that we dub ‘Moriya’ is used by an unknown actor to deploy passive backdoors on public facing servers,\\n\\n            facilitating the creation of a covert C&C communication channel through which they can be silently controlled;\\n            The rootkit was found on networks of regional diplomatic organizations in Asia and Africa, detected on several instances dating\\n            back to October 2019 and May 2020, where the infection persisted in the targeted networks for several months after each\\n            deployment of the malware;\\n\\n            We observed an additional victim in South Asia, where the threat actor deployed a broad toolset for lateral movement along with\\n            the rootkit, including a tool that was formerly used by APT1. Based on the detection timestamps of that toolset, we assess that the\\n            attacker had a foothold in the network from as early as 2018;\\n            A couple of other tools that have significant code overlaps with Moriya were found as well. These contain a user mode version of\\n\\n            the malware and another driver-based utility used to defeat AV software.\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   2/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        We provided information about this operation in our threat intelligence portal in August 2020. More details and analysis are available to\\n        customers of our private APT reporting service. For more details contact: intelreports@kaspersky.com.\\n\\n        What  is the Moriya rootkit and how does it work?\\n\\n\\n        Our investigation into the TunnelSnake campaign started from a set of alerts from our product on a detection of a unique rootkit within\\n        the targeted networks. Based on string artefacts within the malware’s binaries, we named this rootkit Moriya. This tool is a passive\\n        backdoor which allows attackers to inspect all incoming traffic to the infected machine, filter out packets that are marked as designated\\n        for the malware and respond to them. This forms a covert channel over which attackers are able to issue shell commands and receive\\n\\n        back their outputs.\\n\\n        The rootkit has two traits that make it particularly evasive. The packet inspection happens in kernel mode with the use of a Windows\\n        driver, allowing attackers to drop the packets of interest before they are processed by the network stack, thus ensuring they are not\\n        detected by security solutions. Secondly, the fact that the rootkit waits for incoming traffic rather than initiating a connection to a server\\n\\n        itself, avoids the need to incorporate a C&C address in the malware’s binary or to maintain a steady C&C infrastructure. This hinders\\n        analysis and makes it difficult to trace the attacker’s footprints.\\n\\n        The figure below illustrates the structure of the rootkit’s components. They consist of a kernel mode driver and a user mode agent that\\n        deploys and controls it. In the following sections we will break down each of these components and describe how they operate to achieve\\n\\n        the goal of tapping into the target’s network communication and blending in its traffic.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   3/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 1. The architecture of the Moriya rootkit\\n\\n\\n        User mode agent analysis\\n\\n        The user mode component of the Moriya rootkit has two purposes. One is to deploy the kernel mode component of the malware on the\\n        machine and the other is to leverage the covert communication channel created by it to read shell commands sent from the C&C server\\n        to the compromised machine and to respond to them. Since Moriya is a passive backdoor intended to be deployed on a server accessible\\n\\n        from the internet, it contains no hardcoded C&C address and relies solely on the driver to provide it with packets filtered from the\\n        machine’s overall incoming traffic.\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   4/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        The first order of business for the attacker when using Moriya is to gain persistence on the targeted computer. For this purpose, the user\\n        mode agent’s DLL contains an export function named Install, which is intended to create a service named ZzNetSvc with the description\\n        ‘Network Services Manager’ and start it. In turn, the path to the user mode agent’s image is set to the registry key\\n        HKLM\\\\System\\\\CurrentControlSet\\\\Services\\\\ZzNetSvc\\\\Parameters\\\\ServiceDll so that it will be invoked from its ServiceMain export\\n\\n        each time the service is initiated.\\n\\n        Next, after the service is started, the agent will attempt to load the rootkit’s driver into the system. Its binary is bundled as two driver\\n        images within the DLL’s resource section, corresponding to 32- and 64-bit architectures, while in reality only one of them is written to\\n        disk. In the cases we analyzed, the agent DLLs were compiled for 64-bit systems, dropping a 64-bit driver to the drivers directory in the\\n\\n        system path, under the name MoriyaStreamWatchmen.sys, hence the rootkit’s name.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 2. Code that writes the Moriya driver to disk\\n\\n        The agent uses a known technique whereby the VirtualBox driver (VBoxDrv.sys) is leveraged to bypass the Driver Signature\\n        Enforcement mechanism in Windows and load Moriya’s unsigned driver. DSE is an integrity mechanism mandating that drivers are\\n\\n        properly signed with digital signatures in order for them to be loaded, which was introduced for all versions of Windows starting from\\n        Vista 64-bit. The technique used to bypass it was seen in use by other threat actors like Turla, Lamberts and Equation.\\n\\n        Moriya’s user mode agent bypasses this protection with the use of an open-source code[1] named DSEFIX v1.0. The user agent dumps an\\n        embedded VBoxDrv.sys image of version 1.6.2 to disk and loads it, which is then used by the aforementioned code to map Moriya’s\\n\\n        unsigned driver to kernel memory space and execute it from its entry point. These actions are made possible through IOCTLs\\n        implemented in VBoxDrv.sys that allow writing to kernel address space and executing code from it. Throughout this process, the bypass\\n        code is used to locate and modify a flag in kernel space named g_CiOptions, which controls the mode of enforcement.\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   5/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        After the unsigned driver is loaded, the agent registers a special keyword that is used as a magic value, which will be sought in the first\\n        bytes of every incoming packet passed on the covert channel. This allows the rootkit to filter marked packets and block them for any\\n        application on the system other than the user mode agent. The registration of the value is done through a special IOCTL with the code\\n        0x222004 sent to the driver, where a typical magic string is pass12.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 3. Registration of the packet magic value using a designated IOCTL\\n\\n        Except for its covert channel communication feature, Moriya is capable of establishing a reverse shell session using an overt channel.\\n        For this purpose, it waits for a special packet that consists of a message with the structure connect <c2_address> <c2_port>. The\\n        address and port are parsed and used by the agent to start a new connection to the given server, while creating a new cmd.exe process\\n\\n        and redirecting its I/O to the connection’s socket. The handles for the newly created process and its main thread are destroyed to avoid\\n        detection.\\n\\n        In any other case, the agent attempts to read the incoming TCP payload from the driver, which will be retrieved as soon as a designated\\n        packet with a magic number and shell command is received. An attempt is made to read the data with a plain ReadFile API function as a\\n\\n        blocking operation, i.e., reading is accomplished only once the buffer in kernel mode is populated with data from a Moriya-related\\n        packet.\\n\\n        Upon an incoming packet event, the agent creates a new cmd.exe process and redirects its I/O using named pipes. One pipe is used to\\n        read the retrieved shell command from the covert channel and the other is used to write the shell’s output (obtained from the stdout and\\n\\n        stderr streams) back to it after execution. To write any data back, the agent uses the WriteFile API function with the driver’s handle.\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   6/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        All traffic passed on the channel is encoded with a simple encryption scheme. Every sent byte has its payload, following the magic string,\\n        XORed with the value 0x05 and then negated. Following the same logic, to decode the incoming traffic’s payload, every byte of it should\\n        be first negated and then XORed with 0x05.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 4. Code used for packet encoding\\n\\n\\n        Kernel mode driver analysis\\n\\n        The Moriya rootkit’s driver component makes use of the Windows Filtering Platform (WFP) to facilitate the covert channel between the\\n        compromised host and the C&C server. WFP provides a kernel space API that allows driver code to intercept packets in transit and\\n        intervene in their processing by the Windows TCP/IP network stack. This makes it possible to write a driver that can filter out distinct\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   7/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        packet streams, based on developer-chosen criteria, and designate them for consumption by a specific user mode application, as is the\\n        case in Moriya.\\n\\n        The driver fetches the distinct Moriya-related traffic using a filtering engine. This is the kernel mode mechanism used to inspect traffic\\n        according to rules that can be applied on various fields across several layers of a packet (namely data link, IP and transport), making it\\n\\n        possible to handle matching packets with unique handlers. Such handlers are referred to as callout functions.\\n\\n        In the case of Moriya, the filtering engine is configured to intercept TCP packets, sent over IPv4 from a remote address. Each packet\\n        with these criteria will be inspected by a callout function that checks if its first six bytes correspond to the previously registered magic\\n        value, and if so, copies the packet contents into a special buffer that can be later read by the user mode agent. The matching packet will\\n\\n        then be blocked in order to hide its presence from the system, while any other packet is permitted to be processed as intended by the\\n        network stack.\\n\\n        To allow the crafting of a response back to the server, the callout function saves a special value in a global variable that identifies the\\n        received TCP stream. This value is called a flowHandle, and is taken from the packet’s corresponding\\n\\n        FWPS_INCOMING_METADATA_VALUES0    struct. When the user issues a response to the server via the driver, the latter would craft a\\n        new packet using the FwpsAllocateNetBufferAndNetBufferList0 function and insert the response data and target server based on the\\n        saved flowHandle to it, using the function FwpsStreamInjectAsync0.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   8/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 5. Code that creates a new packet, designates it for the flow of the corresponding incoming TCP packet and\\n        injects data written from user space into it\\n\\n\\n        As formerly mentioned, the driver registers several functions that are exposed to the user mode agent in order to interact with it:\\n\\n            IRP_MJ_READ:   used to allow the user mode agent to read the body of a Moriya TCP packet from a special buffer to which it is\\n            copied upon receipt. The function itself waits on an event that gets signaled once such a packet is obtained, thus turning the\\n            ReadFile function called by the user mode agent into a blocking operation that will wait until the packet is picked up by the driver.\\n\\n            IRP_MJ_WRITE:   injects user-crafted data into a newly created TCP packet that is sent as a response to an incoming Moriya\\n            packet from the server.\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   9/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            IRP_MJ_DEVICE_CONTROL:    used to register the keyword to check the beginning of every incoming TCP packet in order to\\n            identify Moriya-related traffic. The passed magic is anticipated to be six characters long.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 6. Code used for registering the packet magic value from the driver side\\n\\n        How  were targeted servers initially infected?\\n\\n\\n        Inspecting the systems targeted by the rootkit, we tried to understand how they got infected in the first place. As previously mentioned,\\n        Moriya was seen deployed mostly on public-facing servers within the victim organizations. In one case, we saw the attacker infect an\\n        organizational mail server with the China Chopper webshell, using it to map the victim’s\\n\\n        network and then deploy other tools in it. Moriya’s user mode agent was explicitly installed using a command line executed on the\\n\\n        targeted server this way. This command and examples of others run on the victim machine via the webshell can be seen below.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   10/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n         1   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&ipconfig -all\\n\\n         2   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&reg query\\n\\n         3   HKLM\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\SecurityProviders\\\\WDigest\\n\\n         4   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&$public\\\\acmsetup.exe\\n\\n         5   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&query user\\n\\n         6   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&ipconfig/all\\n\\n         7   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&ping google.com\\n\\n         8   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&netstat -anp tcp\\n\\n         9   \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&tasklist /v\\n\\n         10  \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&whoami\\n\\n         11  \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&cd $windir\\\\web\\\\\\n         12  \"cmd\" /c cd /d $windir\\\\Web\\\\&rundll32 MoriyaServiceX64.dll, Install\\n\\n         13  \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&ipconfig/all\\n\\n         14  \"cmd\" /c cd /d C:\\\\inetpub\\\\wwwroot\\\\&time /t\\n\\n         15 ...\\n\\n\\n\\n        In general, we assess that the group’s modus-operandi involves infiltrating organizations\\n\\n        through vulnerable web servers in their networks. For example, an older variant of Moriya named IISSpy (described below) targets IIS\\n        web servers. Our telemetry shows that it was likely deployed by exploiting CVE-2017-7269 to let the attackers gain an initial foothold on\\n\\n        a server prior to running the malware.\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   11/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n        Post exploitation toolset\\n\\n\\n        During our investigation we found a target in South Asia that enabled us to get a glimpse into some of the other tools that we assess were\\n        in use by the same attacker. The toolset includes programs used to scan hosts in the local network, find new targets, perform lateral\\n        movement to spread to them and exfiltrate files. While most of the tools seem custom made and tailored for the attackers’ activities, we\\n\\n        could also observe some open-source malware frequently leveraged by Chinese-speaking actors. Following is an outline of these tools\\n        based on their purpose in the infection chain.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   12/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            Network Discovery: custom built programs used to scan the internal network and detect vulnerable services.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   13/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                HTTP  scanner: command-line tool, found under the name ‘8.tmp’, which discovers web servers through banner grabbing.\\n                This is done by issuing a malformed HTTP packet to a given address, where no headers are included and the request is\\n                succeeded with multiple null bytes.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Fig. 7. Malformed packet generated by HTTP scanner\\n\\n                If the server responds, the output will be displayed in the console, as shown below.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   14/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                Fig. 8. Console output with a server response displayed upon discovery of a new server in the network\\n\\n                DCOM   Scanner: another command-line utility that attempts to connect to a remote host on TCP port 135 (RPC), and use\\n                the DCOM IOxidResolver interface to resolve addresses assigned to all network interfaces available on the remote system.\\n\\n                Fig. 9. Output of the DCOM scanner utility\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   15/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            Lateral Movement: tools used to spread to other hosts in the targeted networks.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   16/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                BOUNCER:  malware that was first described by Mandiant in their 2013[2] report on APT1. This tool is another passive\\n                backdoor that waits for incoming connections on a specific port and provides different features, as outlined below, that can\\n                be used to control a remote host and facilitate lateral movement from it.\\n\\n\\n                 1   0x01: Proxy Init Connection\\n\\n                 2          0x02: Proxy Send Packet\\n\\n                 3          0x03: Proxy Close Connection\\n                 4          0x07: Execute Shellcode\\n\\n                 5          0x0A: Kill Bot\\n\\n                 6          0x0C: Reverse Shell CMD\\n\\n                 7          0x0D: Delete File\\n\\n                 8          0x0E: Execute local program\\n\\n                 9          0x0F: Enumerate Servers In Domain and save output in gw.dat\\n\\n                 10         0x10: Enumerate SQL Servers and save output in sql.dat\\n\\n                 11         0x12: Reverse Shell CreateProcess\\n\\n                 12         0x16: Upload File - Write Data\\n\\n                 13         0x17: Download File - Finish\\n\\n                 14         0x1E: Download File - Start\\n\\n                 15         0x1F: Upload File - Start\\n\\n                 16         0x2D: Enumerate Servers\\n\\n                 17         0x2E: Enumerate SQL Server\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   17/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n                 18         0x2F: Enumerate Servers Verbose\\n\\n                 19         0x30: Enumerate Users\\n\\n                 20         0x32: Do nothing\\n\\n\\n\\n                The BOUNCER sample that we observed contained a string that indicates which command-line arguments it anticipates:\\n\\n                 1  usage:%s IP port [proxip] [port] [key]\\n\\n\\n\\n                However, the backdoor is configured to accept only the port number on which it will listen.\\n                We saw two versions of this backdoor, initiated by two different launchers. The first one is an executable file named nw.tmp\\n                that decrypts an embedded payload using the RC4 algorithm and injects it into a newly spawned svchost.exe process. The\\n\\n                injected payload is similar to one described by Mandiant in 2013, which is yet another intermediate loader that decrypts and\\n                loads an embedded BOUNCER DLL. The last stage is started by invoking the DLL’s dump export with the arguments passed\\n                via the command line.\\n\\n                The other version was stored with the name rasauto.dll in the system directory, impersonating the Windows Remote Access\\n\\n                Auto Connection Manager library. Like the other version, it decrypts an embedded DLL using RC4, but this time uses no\\n                intermediate stage, instead directly calling the DLL’s dump export without arguments. The decrypted library is a slightly\\n                modified BOUNCER variant that always listens on the hardcoded port 1437.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   18/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Fig. 10. Code from the second BOUNCER variant that uses the hardcoded port 1437 to listen for new\\n\\n                packets\\n\\n                Based on compilation timestamps of all BOUNCER-related executables, as shown below, we assess that the attacker reused\\n                old samples of the malware rather than compiled new versions of it:\\n\\n\\n                 1  nw.tmp – stage 0 - launcher - 08-03-2017 03:56:24\\n\\n                 2         nw.tmp – stage 1 - embedded loader - 26-08-2014 04:49:58\\n\\n                 3         nw.tmp – stage 2 - embedded BOUNCER backdoor - 28-05-2012 13:44:37\\n                 4\\n\\n                 5         rasauto.dll - stage 0 – loader 26-08-2013 09:37:08\\n\\n                 6         rasauto.dll - stage 1 - embedded BOUNCER backdoor - 26-08-2013 09:36:27\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   19/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                Custom PSExec: the attacker deployed a tool to execute commands remotely on compromised machines. Like the original\\n                PSExec tool, this one consists of two components – a client named tmp and a service named pv.tmp. In order to use the tool,\\n                the attacker has to execute it via a command line with the parameters specified below.\\n\\n\\n                 1  Usage: psexec <hostname > psserve_path exefilename ServerName[option]\\\\n\\n\\n\\n                The service component is a tiny program that uses the CreateProcessA API to start a program specified as an argument. The\\n                client component uses the Service Control Manager (SCM) API to create a service on the target machine. If the ServerName\\n\\n                argument is not specified, the service will be named Server%c%c where %c is a random lower case character. The\\n                exefilename argument is then passed to the StartServiceA function in order to initiate the command execution.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Fig. 11. Code used to create and start the service on targeted host\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   20/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                It is worth noting that the program has some limitations. Compared with the original PSExec, it is not able to copy the\\n                service binary (i.e., pv.tmp, which has its path specified in the psserve_path argument) to a remote machine, but rather\\n                assumes it is already present on it. Besides, it cannot handle network credentials, limiting the ability to execute commands as\\n                other users, nor does it support pipes, which means it does not receive the output of the commands it issues.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   21/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            Exfiltration: multi-platform utilities commonly used to establish connections with remote hosts and conduct file system\\n            operations on them, including file upload and download.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   22/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                Earthworm  and Termite: well-known command-line utilities developed to facilitate intrusion into intranet networks.\\n                These programs are multiplatform and can be deployed on various architectures. Earthworm is used to create tunnels\\n                between compromised hosts and transfer data.\\n\\n                Fig. 12. Earthworm help message\\n\\n                Termite provides additional features to download and upload files\\n\\n                between the compromised hosts, as well as a way to spawn a remote\\n                shell to control the targeted machine.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   23/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Fig. 13. Termite help message\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   24/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n                TRAN:  another tool that we detected under the filename tmp that was used to transfer data between compromised hosts.\\n                The binary we saw operated as a loader that embodies a tiny web server encrypted with the RC4 algorithm within it. This\\n                server is later injected into a newly created legitimate schtask.exe process and usually listens on port 49158. It is used for\\n                managing files uploaded by the attacker into an in-memory virtual file system maintained by the malware.By default the file\\n\\n                system includes a tiny program named client.exe, which can be downloaded by any host using a standard HTTP GET request\\n                to the path /client.exe. This file is a command-line utility that can be used to control the virtual file system managed by the\\n                server, through one of several available commands outlined below.\\n\\n\\n\\n\\n                Fig. 14. Client.exe help message\\n\\n\\n        IISSpy: tracing Moriya back to a user-mode rootkit\\n\\n        IISSpy is an older user-mode version of the Moriya rootkit that we were able to pinpoint in our telemetry. It is used to target IIS servers\\n        for establishing a backdoor in their underlying websites. It was detected on a machine in 2018, unrelated to any of the attacks in the\\n\\n        current operation. This suggests the threat actor has been active since at least that year.\\n\\n        The malware, which comes as a DLL, achieves its goals by enumerating running IIS processes on the server (i.e., those that are executed\\n        from the image w3wp.exe), and injecting the malware’s DLL into them to alter their behavior. The executed code in the IIS processes\\n        will then set inline hooks for several functions, most notably CreateFileW.\\n\\n        The corresponding CreateFileW hook function checks if the filename argument contains the directory ‘\\\\MORIYA\\\\’ or ‘\\\\moriya\\\\’ in its\\n\\n        path, and if so, infers that the attacker has sent a specially crafted HTTP request to the web server. In this request, the Moriya path in\\n        the URL is followed by an encoded command. After the command is decoded and processed, it is passed via a mailslot\\n        (\\\\\\\\.\\\\mailslot\\\\slot) to a separate thread, while signaling an event called Global\\\\CommandEvent.\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   25/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 15. Code of the CreateFileW hook function that looks for the ‘MORIYA’ \\\\ ‘moriya’ directory in a request path\\n\\n        Should the currently handled file contain the Moriya path, the very same hook function will generate a special file on the web server to\\n        which command execution output will be written. This file’s path is created by finding the position of the ‘\\\\MORIYA\\\\’ or ‘\\\\moriya\\\\’\\n\\n        strings in the inspected filename argument, and replacing it with the string ‘\\\\IISINFO.HTM’. This will then be appended to the\\n        command data passed on the mailslot, following a ‘ > ‘ character.\\n\\n        The other thread waiting on the command event mentioned above is in charge of processing attacker data fetched from the mailslot. Any\\n        such command will be read and parsed to find the ‘ > ‘ character and the file path that follows it, in this case the one corresponding to\\n\\n        ‘IISINFO.HTML’. After executing the command via cmd.exe, the output will be written to the file in this path, allowing the attacker to\\n        read it by issuing a corresponding HTTP request where the URL path leads to this file on the server.\\n\\n        Other functions that are hooked in the IIS process are CreateProcessAsUserW and CreateProcessW. These are used to detect if the\\n        current process spawns a new server instance, which will in turn be injected with the malware’s DLL. Apart from this, IISSpy will also\\n\\n        create a monitoring thread that will periodically look for newly created httpd.exe processes, corresponding to the Apache server. If\\n        detected, the malware will be injected to them as well.\\n\\n        Although it is evident from both the functionality and use of the Moriya keyword by the malware that IISSpy and the Moriya rootkit are\\n        related, further evidence in the code substantiates the connection:\\n\\n\\n            The older variant is capable of creating a reverse shell transmitted through an overt channel in exactly the same way as the more\\n            recent version of the malware, i.e., it identifies a connect request followed by a C&C server address and port, connects to it and\\n            redirects the IO of a new exe process to the underlying socket.\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   26/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            Both variants use the same packet encoding and decoding algorithm, whereby each clear-text byte is XORed with 0x5 and negated,\\n            and vice-versa.\\n\\n        Fig. 16. Packet decoding loop that follows the same logic as that used in Moriya\\n\\n            In both cases the developers left a trail of unique debug messages, issued to the\\n            OutputDebugString API function. An example of such a string used in identical code in the\\n\\n            two variants is shown below.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   27/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Fig. 17. Code used in both variants to spawn a new shell, while printing unique debug messages\\n\\n            Both implants are deployed by invoking an export function named Install that creates a service that allows persistent execution,\\n            with the malware’s logic residing in the ServiceMain Moreover, the Install functions are highly similar to one another.\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   28/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        Fig. 18. Comparison of Install export function CFGs between IISSpy and\\n        Moriya\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        The ProcessKiller rootkit vs. security products\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   29/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        Another interesting artefact found in our telemetry that could be tied to the developers of Moriya is a malware named ProcessKiller. As\\n        its name suggests, it is intended to eliminate execution of processes, with the use of a kernel mode driver. Ultimately, this tool is used to\\n        shut down and block initiation of AV processes from kernel space, thus allowing other attack tools to run without being detected.\\n\\n        This malware operates through the following stages:\\n\\n            An attacker calls the malware’s DLL from an export named Kill, passing it a list of process names it would like to shut down and\\n\\n            block as a command-line argument.\\n            The malware writes a driver that is embedded as a resource within it, impersonating a Kaspersky driver under the path\\n            %SYSTEM%\\\\drivers\\\\kavp.sys.\\n\\n            There is an attempt to load the driver using the Service Control Manager. However, since it is not signed and loading is prone to\\n            fail on Windows versions above Vista 64-bit, the malware uses the same DSEFix code to bypass Digital Signature Enforcement as\\n            witnessed in Moriya’s user mode agent.\\n            The malware parses the process names passed as arguments and creates a vector of ‘blacklisted processes’ out of them.\\n\\n            For each process in the list, the malware detects its PID and issues it through an IOCTL with code 0x22200C to the driver which is\\n            in charge of shutting it down from kernel space. The shutdown is carried out by locating the process object with the function\\n            PsLookupProcessByProcessId and then terminating it with ZwTerminateProcess.\\n            The list of processes is then passed via another IOCTL with the code 0x222004 to the driver, which inserts each member of it to a\\n\\n            linked list in kernel space. When the driver is bootstrapped, it registers a callback for newly created processes through the\\n            PsSetCreateProcessNotifyRoutineEx function, which inspects the image name of the created process and compares it against those\\n            found in the linked list. If a match is found, the process creation status in the PPS_CREATE_NOTIFY_INFO structure will be set\\n            to STATUS_UNSUCCESSFUL, signaling the user space API function that process creation failed.\\n\\n            At this point any other malware can theoretically operate without being detected.\\n            If the attacker wishes to disable blacklisting, it can be done by issuing an IOCTL with the code 0x222008, which would destroy the\\n            linked list of blacklisted processes.\\n\\n        Once again, the connection to Moriya is based on several observations:\\n\\n\\n            Distinct debug error messages, as the one presented below.\\n\\n        Fig. 19. Unique debug message that appears in ProcessKiller and Moriya\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   30/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n            Filename of the same structure, i.e., Moriya’s agent is internally named\\n            ‘MoriyaServiceX64.dll’, and ProcessKiller’s DLL is named ‘ProcessKillerX64.dll’\\n            Usage of the exact same DSEFix code to load an unsigned driver.\\n\\n\\n\\n\\n\\n        What  do we know  about the threat actor?\\n\\n        Unfortunately, we are not able to attribute the attack to any particular known actor, but based on the TTPs used throughout the\\n        campaign, we suppose it is a Chinese-speaking one. We base this on the fact that the targeted entities were attacked in the past by\\n\\n        Chinese-speaking actors, and are generally located in countries that are usually targeted by such an actor profile. Moreover, the tools\\n        leveraged by the attackers, such as China Chopper, BOUNCER, Termite and Earthworm, are an additional indicator supporting our\\n        hypothesis as they have previously been used in campaigns attributed to well-known Chinese-speaking groups.\\n\\n\\n        Who  were  the targets?\\n\\n        Based on our telemetry the attacks were highly targeted and delivered to less than 10 victims around the world. The most prominent\\n        victims are two large regional diplomatic organizations in South-East Asia and Africa, while all the others were victims in South Asia.\\n\\n\\n        Conclusion\\n\\n        The TunnelSnake campaign demonstrates the activity of a sophisticated actor that invests significant resources in designing an evasive\\n        toolset and infiltrating networks of high-profile organizations. By leveraging Windows drivers, covert communications channels and\\n\\n        proprietary malware, the group behind it maintains a considerable level of stealth. That said, some of its TTPs, like the usage of a\\n        commodity webshell and open-source legacy code for loading unsigned drivers, may get detected and in fact were flagged by our\\n        product, giving us visibility into the group’s operation.\\n\\n        Still, with activity dating back to at least 2018, the threat actor behind this campaign has shown that it is able to evolve and tailor its\\n\\n        toolset to target environments. This indicates the group conducting these attacks may well still be active and retooling for additional\\n        operations in the area of interest outlined in this publication, as well as other regions. With that in mind, we continue to track this\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   31/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        attacker and look for signs of its reappearance in the wild. Any findings and updates will be made available to customers of our Threat\\n        Intelligence Portal.\\n\\n        For more information about operation TunnelSnake and the underlying threat actor, contact us at: intelreports@kaspersky.com.\\n        To learn more on reverse engineering and malware analysis from Kaspersky GReAT experts, check out the website\\n\\n        http://xtraining.kaspersky.com.\\n\\n        IOCs\\n\\n\\n         48307C22A930A2215F7601C78240A5EE   Moriya Agent\\n\\n         A2C4EE84E3A95C8731CA795F53F900D5   Moriya 64-bit Driver\\n\\n         5F0F1B0A033587DBCD955EDB1CDC24A4   IISSpy\\n\\n         C1159FE3193E8B5206006B4C9AFBFE62   ProcessKiller\\n\\n         DA627AFEE096CDE0B680D39BD5081C41   ProcessKiller Driver – 32-bit\\n\\n         07CF58ABD6CE92D96CFC5ABC5F6CBC9A   ProcessKiller Driver – 64-bit\\n\\n         9A8F39EBCC580AA56D6DDAF5804EAE61   pv.tmp (Custom PSExec Server)\\n\\n         39C361ABB74F9A338EA42A083E6C7DF8   pc.tmp (Custom PsExec Client)\\n\\n         DE3FB65461EE8A68A3C7D490CDAC296D   tran.tmp (Exfiltration tool)\\n\\n         EAC0E57A22936D4C777AA121F799FEE6   client.exe (Utility embedded in tran.tmp)\\n\\n         D745174F5B0EB41D9F764B22A5ECD357   rasauto.dll (Bouncer Loader)\\n\\n         595E43CDF0EDCAA31525D7AAD87B7BE4   8.tmp (HTTP )Scanner\\n\\n         9D75B50727A8E732DB0ADE7E270A7395   ep.tmp DCOM Scanner\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   32/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n         3A4E1F3F7E1BAAB8B02F3A8EE20F98C9   nw.tmp Bouncer Loader\\n\\n         47F2D06713DAD556F535E523B777C682   Termite\\n\\n         45A5D9053BC90ED657FA90DE0B775E8F   Earthworm\\n\\n        [1] Today a copy of the original code can be found here: http://www.m5home.com/bbs/thread-8043-1-1.html\\n\\n\\n        [2] https://www.fireeye.com/content/dam/fireeye-www/services/pdfs/mandiant-apt1-report.pdf\\n\\n        Operation TunnelSnake\\n\\n        Your email address will not be published. Required fields are marked *\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   33/33\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it created a proper-length thing, but put the end-of-text indicator right at the beginning, and all spaces after that. weird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n        Operation    TunnelSnake\\n\\n\\n          securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Formerly  unknown  rootkit used to secretly control networks of regional organizations\\n\\n\\n\\n\\n\\n    https://securelist.com/operation-tunnelsnake-and-moriya-rootkit/101831/                                   1/33\\n    5/7/2021                                          Operation TunnelSnake | Securelist\\n\\n\\n\\n        Windows rootkits, especially those operating in kernel space, are pieces of malware infamous for their near absolute power in the\\n        operating system. Usually deployed as drivers, such implants have high privileges in the system, allowing them to intercept and\\n        potentially tamper with core I/O operations conducted by the underlying OS, like reading or writing to files or processing incoming and\\n        outgoing network packets. The capability to blend into the fabric of the operating system itself, much like security products do, is the\\n\\n        quality that earns rootkits their notoriety for stealth and evasion.\\n\\n        Having said that, the successful deployment and execution of a rootkit component in Windows has become a difficult task over the\\n        years. With Microsoft’s introduction of Driver Signature Enforcement, it has become harder (though not impossible) to load and run\\n        new code in kernel space. Even then, other mechanisms such as Kernel Patch Protection (also known as PatchGuard) make it hard to\\n\\n        tamper with the system, with every change in a core system structure potentially invoking the infamous Blue Screen of Death.\\n\\n        Consequently, the number of Windows rootkits in the wild has decreased dramatically, with the bulk of those still active often being\\n        leveraged in high profile APT attacks. One such example came to our attention during an investigation last year, in which we uncovered\\n        a formerly unknown Windows rootkit and its underlying cluster of activity. We observed this rootkit and other tools by the threat actor\\n\\n        behind it being used as part of a campaign we dubbed ‘TunnelSnake’, conducted against several prominent organizations in Asia and\\n        Africa.\\n\\n        In this blog post we will focus on the following key findings that came up in our investigation:\\n\\n            A newly discovered rootkit that we dub ‘Moriya’ is used by an unknown actor to deploy passive backdoors on public facing servers,\\n\\n            facilitating the creation of a covert C&C communication channel through which they can be silently controlled;\\n            The rootkit was found on networks of regional diplomatic organizations in Asia and Africa, detected on several instances dating\\n            back to October 2019 and May 2020, where the infection persisted in the targeted networks for several months after each\\n            deployment of the malware;\\n\\n            We observed an additional victim in South Asia, where the threat actor deployed a broad toolset for lateral movement along with\\n            the rootkit, including a tool that was formerly used by APT1. Based on the detection timestamps of that toolset, we assess that the\\n            attacker had a foothold in the network from as early as 2018;\\n            A couple of'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's true that a lot of the early characters here are spaces, so that part isn't *wrong* per-se, but why is it putting the <endoftext> token right at the beginning? So strange. In any case, it looks like it's tokenizing properly...those are valid tensors, it decodes back to what it was supposed to be. It's just the generation that's busted. Why?\n",
    "    \n",
    "Let's try a prompt that's just a minor modification of an existing one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 52])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"1/17/2022                                          Operation Underpants Gnomes\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(None, min_length=1000, max_length=1000, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh. Apparently GPT2 is looking for `<|startoftext|>` and `<|endoftext|>` markers on every sample in training, so it believes it was trained with a bunch of empty data. Need to re-read the initial input all over again, and add those tags into the text. \n",
    "\n",
    "(source: https://towardsdatascience.com/how-to-fine-tune-gpt-2-so-you-can-generate-long-form-creative-writing-7a5ae1314a61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            data = \"<|startoftext|>\" + infile.read() + \"<|endoftext|>\"\n",
    "            values.append(data)\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1454' class='' max='1454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1454/1454 01:21<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=6.30957365501672e-05)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqgUlEQVR4nO3deXxc5X3v8c9vtFirZVuWvMm2vGIbL9gRZidsIQkQoEkItGkIvaQ0S5OmNzdp0vaShJu+bnqT21BIGiChgSYk4OuEBAiEfTEYbGRjG4x3ed80kmxZi7XO7/4xIxBCkmVLZ2Y0832/mJfOnPOcc36PB81P5zzPeR5zd0REJL2FEh2AiIgknpKBiIgoGYiIiJKBiIigZCAiIigZiIgIkJnoAE7W2LFjvby8PNFhiIgMK2vWrKlx95K+tg+7ZFBeXk5lZWWiwxARGVbMbHd/23WbSERElAxERETJQEREGIZtBr1pb29n3759tLS0JDqUhMnJyaGsrIysrKxEhyIiw1BKJIN9+/ZRWFhIeXk5ZpbocOLO3amtrWXfvn1MmzYt0eGIyDCUEreJWlpaKC4uTstEAGBmFBcXp/WVkYgMTqDJwMx2mdmbZrbOzN7XH9TMLjKz+tj2dWZ26yDONbhgh7l0r79Iqnv67cNsr24M7PjxuDK42N3PcPeKPraviG0/w91vi0M8CVdQUADArl27mD9/foKjEZFkF4k4X3xgDb9duy+wc6TEbaKTtmEZ/Gg+fGdU9OeGZYmOSESkT/XH22nvdEoKRgR2jqCTgQNPmdkaM7uljzLnmNl6M3vCzE7vrYCZ3WJmlWZWGQ6HBxfRhmXw6Fegfm80vPq90feDSAjf/OY3+clPfvLO++985zt873vf49JLL2XJkiUsWLCAP/zhD/0eo7Ozk69//euceeaZLFy4kLvvvhuAG2+8kd///vfvlPv0pz99wmOJSGoJN7YCUDpy+CaD8919CfBR4EtmdmGP7WuBqe6+CLgT+H1vB3H3e9y9wt0rSkr6HFpjYJ69DdqPv3dd+/Ho+lN0/fXXs2zZu8lk2bJlfPazn+Xhhx9m7dq1PP/883zta1+jvylG7733XoqKinj99dd5/fXX+dnPfsbOnTu5+eabue+++wCor69n5cqVXHnllaccq4gMP+GGaDII8sog0K6l7r4/9rPazB4GlgIvddt+rNvy42b2H2Y21t1rAguqvo97bn2tH4DFixdTXV3NgQMHCIfDjB49mvHjx/P3f//3vPTSS4RCIfbv38/hw4cZP358r8d46qmn2LBhA8uXL4+GU1/Ptm3buPzyy/niF79IOBzmt7/9LZ/4xCfIzEyJHsEiMkDVDdGegiWFwzAZmFk+EHL3htjy5cBtPcqMBw67u5vZUqJXKrVBxQRAUVnsFlEv6wfhuuuuY/ny5Rw6dIjrr7+eBx54gHA4zJo1a8jKyqK8vLzfrp/uzp133smHP/zh92278cYb+dWvfsWDDz7IL37xi0HFKSLDzztXBgEmgyBvE40DXjaz9cBq4I/u/icz+7yZfT5W5pPAW7EydwA3eH/3UobCpbdCVu5712XlRtcPwvXXX8+DDz7I8uXLue6666ivr6e0tJSsrCyef/55du/ud8BAPvzhD/PTn/6U9vZ2ALZu3UpTUxMAN910E7fffjsA8+bNG1ScIjL8hBtayckKUTAiuLsCgR3Z3auARb2sv6vb8o+BHwcVQ68Wfir689nboreGisqiiaBr/Sk6/fTTaWhoYNKkSUyYMIFPf/rTfOxjH2PBggVUVFQwZ86cfvf/3Oc+x65du1iyZAnuTklJyTsNx+PGjWPu3Llce+21g4pRRIancEMrpYU5gT5PZEH/IT7UKioqvOd8Bps2bWLu3LkJiih4zc3NLFiwgLVr11JUVNRnuVT/dxBJV3/xs9do7Yjw2y+ce8rHMLM1/TzvlabPGQwjzzzzDHPnzuXLX/5yv4lARFJXuKE10J5EkCID1aWyyy677ITtDSKS2sKNrZw9vTjQc+jKQEQkibV2dHK0uZ3SAHsSQQolg+HW9jHU0r3+IqmqprENCLZbKaRIMsjJyaG2tjZtvxC75jPIyclJdCgiMsTi8YwBpEibQVlZGfv27WPQ4xYNY10znYlIalEyOAlZWVma4UtEUlJXMigtDPbKPyVuE4mIpKquZFBckB3oeZQMRESSWHVDC2Pys8nKCPbrWslARCSJxeOBM1AyEBFJauHG1sAbj0HJQEQkqUUHqVMyEBFJW+5OdYOuDERE0tqxlg7aOiJKBiIi6SxeD5xBwMnAzHaZ2Ztmts7MKnvZbmZ2h5ltN7MNZrYkyHhERIaTeCaDeDyBfHE/E9x/FJgVe50F/DT2U0Qk7YUbu54+HuZXBgNwDfBfHvUaMMrMJiQ4JhGRpFB9rAWAkoLgB6EMOhk48JSZrTGzW3rZPgnY2+39vtg6EZG0F25sJTsjxMjc4G/iBH2G8919v5mVAk+b2WZ3f+lkDxJLJLcATJkyZahjFBFJSuFYt1IzC/xcgV4ZuPv+2M9q4GFgaY8i+4HJ3d6Xxdb1PM497l7h7hUlJSVBhSsiklTCcXrGAAJMBmaWb2aFXcvA5cBbPYo9AtwY61V0NlDv7geDiklEZDiJZzII8jbROODh2OVNJvBrd/+TmX0ewN3vAh4HrgC2A83AXwUYj4jIsBJuaGXJ1NFxOVdgycDdq4BFvay/q9uyA18KKgYRkeGqvTNCXXNbXEYshcR3LRURkV7UNbXhDqUjlQxERNLWO08f68pARCR9VTfEHjgb7r2JRETk1MVzXCJQMhARSUpKBiIiQrihlaLcLEZkZsTlfEoGIiJJKF4znHVRMhARSULhhta49SQCJQMRkaQUbtSVgYhI2gs3tMZlUpsuSgYiIkmmoaWd5rZOxioZiIikr9eq6gCYP7EobudUMhARSTJPbTzEyJxMzpo+Jm7nVDIQEUkiHZ0Rntl0mEvnjiMrI35f0UoGIiJJpHL3EY40t3P5vHFxPa+SgYhIEnlq42GyM0NcODu+U/wqGYiIJAl356m3D3HBzLHkjwhyIsr3CzwZmFmGmb1hZo/1su0mMwub2brY63NBxyMikqw2HWxg35HjXH56fG8RQbBzIHf5O2ATMLKP7Q+5+9/GIQ4RkaT21NuHMINL58Y/GQR6ZWBmZcCVwM+DPI+ISCp4auNhKqaOZmwcxyTqEvRtotuBbwCRfsp8wsw2mNlyM5vcWwEzu8XMKs2sMhwOBxGniEhC7a1r5u2Dx7h83viEnD+wZGBmVwHV7r6mn2KPAuXuvhB4Gri/t0Lufo+7V7h7RUlJfFvYRUTi4em3DwPwoTh3Ke0S5JXBecDVZrYLeBC4xMx+1b2Au9e6e2vs7c+BDwQYj4hI0npy4yFOG1dI+dj8hJw/sGTg7t9y9zJ3LwduAJ5z97/sXsbMJnR7ezXRhmYRkbRS3dDC67vqEtKLqEt8O7ICZnYbUOnujwBfMbOrgQ6gDrgp3vGIiCSSu/PPD79FZijEtYsnJSyOuCQDd38BeCG2fGu39d8CvhWPGEREktGyyr089fZh/umKucwoKUhYHHoCWUQkQXbVNPHdR9/mnOnF3Hz+tITGomQgIpIAHZ0RvvrQOjJDxv/91CJCIUtoPHFvMxAREfjx89tZt/cod/75YiaOyk10OLoyEBGJty2HGrjzue382eJJfGzRxESHAygZiIjE3ZMbDxFx55+vnJvoUN6hZCAiEmev7qhl7viRFCdgDKK+KBmIiMRRS3sna/Yc4ZwZxYkO5T2UDERE4mjtniO0dUQ4Z7qSgYhI2nptRy0hg6XTxyQ6lPdQMhARiaNXq2qZP6mIkTlZiQ7lPZQMRETi5HhbJ+v2Hk26W0SgZCAiEjeVu+to7/SkazwGJQMRkbh5dUctmSHjzPLkai8AJQMRkbhZuaOWhWVF5I9IvpGAlAxEROKgsbWDN/fXJ+UtIlAyEBGJi9d31tEZcc6ZPjbRofQq8GRgZhlm9oaZPdbLthFm9pCZbTezVWZWHnQ8IiKJ8GpVLVkZxgemjk50KL2Kx5XB39H33MY3A0fcfSbwI+Bf4xCPiEjcvbqjlsWTR5ObnZHoUHoVaDIwszLgSuDnfRS5Brg/trwcuNTMEjvDg4jIEKs/3s7GA8nbXgDBXxncDnwDiPSxfRKwF8DdO4B6IHn/tURETsHqnXVEnPRMBmZ2FVDt7muG4Fi3mFmlmVWGw+EhiE5EJH5e3VFLdmaIMyaPSnQofQryyuA84Goz2wU8CFxiZr/qUWY/MBnAzDKBIqC254Hc/R53r3D3ipKSkgBDFhEZeq9V1fKBKaPJyUrO9gIIMBm4+7fcvczdy4EbgOfc/S97FHsE+Gxs+ZOxMh5UTCIi8Xa0uY1Nh44l9S0igLg/BmdmtwGV7v4IcC/wSzPbDtQRTRoiIilj1c463OHsJBycrru4JAN3fwF4IbZ8a7f1LcB18YhBRCQRXquqZURmiEWTixIdSr/0BLKISIBe3VFLRfloRmQmb3sBKBmIiATmSFMbmw81cPa05L5FBEoGIiKBWbWzDkju5wu6KBmIiATktapacrJCLCwblehQTkjJQEQkIK9V1VIxdQzZmcn/VZv8EYqIDEN1sfaC4XCLCJQMREQCsaoqOpjC2dOTb4rL3gwoGZhZvpmFYsuzzexqM8sKNjQRkeHrtapacrMyWDBpVKJDGZCBXhm8BOSY2STgKeAzwH1BBSUiMty9WhV9vmA4tBfAwJOBuXsz8HHgP9z9OuD04MISERm+ahpb2Xq4MemHoOhuwMnAzM4BPg38MbYuuR+nExFJkNXD6PmCLgNNBl8FvgU87O4bzWw68HxgUYmIDFORiHPfyl2MzMlkwaTkHo+ouwENVOfuLwIvAsQakmvc/StBBiYiMhzd+/JOVu+s4wefXEhWxvBoL4CB9yb6tZmNNLN84C3gbTP7erChiYgML1sONfCDJ7dw+bxxfPIDZYkO56QMNG3Nc/djwLXAE8A0oj2KREQEaOuI8NWH1jEyN5P//fEFmFmiQzopA00GWbHnCq4FHnH3dkAzkomIxNz+zFY2HTzG9z++kOKCEYkO56QNNBncDewC8oGXzGwqcCyooEREhpM1u+u468UdXF8xmcvmjUt0OKdkQMnA3e9w90nufoVH7QYu7m8fM8sxs9Vmtt7MNprZd3spc5OZhc1sXez1uVOsh4hIwvz4ue2UFubwPz82L9GhnLIB9SYysyLg28CFsVUvArcB9f3s1gpc4u6NsVtML5vZE+7+Wo9yD7n7355k3CIiSaG9M8KqnXV8YkkZBSPiPq38kBnobaL/BBqAT8Vex4Bf9LdD7AqiMfY2K/ZSO4OIpJT1e4/S3NbJeTOHzwNmvRloMpjh7t9296rY67vA9BPtZGYZZrYOqAaedvdVvRT7hJltMLPlZja5j+PcYmaVZlYZDocHGLKISPBW7qjFDM4aBlNb9megyeC4mZ3f9cbMzgOOn2gnd+909zOAMmCpmc3vUeRRoNzdFwJPA/f3cZx73L3C3StKSkoGGLKISPBe2V7DvAkjGZ2fnehQBmWgyeDzwE/MbJeZ7QJ+DPzNQE/i7keJDl/xkR7ra929Nfb258AHBnpMEZFEO97WyRt7jnLezLGJDmXQBtqbaL27LwIWAgvdfTFwSX/7mFmJmY2KLecCHwI29ygzodvbq4FNAw9dRCSxKnfX0dYZGVYD0vXlpJq+Y08hd/nvwO39FJ8A3G9mGUSTzjJ3f8zMbgMq3f0R4CtmdjXQAdQBN51MPCIiibRyRy2ZIWNp+fCYzaw/g+kH1e+z1u6+AVjcy/pbuy1/i+hoqCIiw87K7TWcMXkU+cO4S2mXwQypp26iIpK26o+38+b+es5NgfYCOMGVgZk10PuXvgG5gUQkIjIMrKqqJeJwbgq0F8AJkoG7F8YrEBGR4WTljlpyskIsnjIq0aEMieEz84KISBJZuaOGM8vHMCIzNWYAVjIQETlJ4YbohPfnzkiN9gJQMhAROWkrd9QAqdNeAEoGIiIn7dUdtRTmZDJ/GE14fyJKBiIiJ8HdeWlrmHOmF5MRGl5TW/ZHyUBE5CRsPtTAgfoWLp1bmuhQhpSSgYjISXhuczUAF5+mZCAikrae21zNgklFlI7MSXQoQ0rJQERkgOqa2nhjzxEunpNaVwWgZCAiMmAvbq0m4nCpkoGISPp6bnOYsQUjWJBCXUq7KBmIiAxAR2eEF7dUc/FpJYRSqEtpFyUDEZEBWLP7CMdaOrgkBW8RQYDJwMxyzGy1ma03s41m9t1eyowws4fMbLuZrTKz8qDiEREZjOc2V5OVYZw/K3XGI+ouyCuDVuCS2NzJZwAfMbOze5S5GTji7jOBHwH/GmA8IiKn7LnN1SydNobCnKxEhxKIwJKBRzXG3mbFXj0nyrkGuD+2vBy41MxS72aciAxre+ua2VbdyCVzxiU6lMAE2mZgZhlmtg6oBp5291U9ikwC9gK4ewdQD6TOMIAikhK6njpO1fYCCDgZuHunu58BlAFLzWz+qRzHzG4xs0ozqwyHw0Mao4jIiTy7uZrpY/OZNjY/0aEEJi69idz9KPA88JEem/YDkwHMLBMoAmp72f8ed69w94qSkpKAoxUReVdbR4TVO2u5cHZqf/cE2ZuoxMxGxZZzgQ8Bm3sUewT4bGz5k8Bz7t6zXUFEJGHe3H+UlvYIZ09P7TvYmQEeewJwv5llEE06y9z9MTO7Dah090eAe4Ffmtl2oA64IcB4RERO2mtVdQCcWT46wZEEK7Bk4O4bgMW9rL+123ILcF1QMYiIDNbqnXXMKi2guGBEokMJlJ5AFhHpQ0dnhMpddZw1fUyiQwmckoGISB/ePniMprZOlk5L7fYCUDIQEenTqlh7wVnTdGUgIpK2Vu2so7w4j3EpNqtZb5QMRER6EYk4r++q46w0uEUESgYiIr3acriB+uPtLE2DW0SgZCAi0qtVVdHBENKhJxEoGYiI9Gr1rjomjcqlbHReokOJCyUDEZEe3J3VO+vSohdRFyUDEZEedoSbqGlsS5v2AlAyEBF5n1U7u9oL0qMnESgZiIi8z+qddZQUjqC8OD3aC0DJQETkPSIRZ1VVtL0gnWbhVTIQEenmyY2HOHSshQ/NS935jnujZCAiEhOJOP/+7Damj83nqoUTEx1OXCkZiIjEPL3pMJsPNfCli2eSEUqfW0SgZCAiAkSfLbjj2W2UF+dxzRnpdVUAwc6BPNnMnjezt81so5n9XS9lLjKzejNbF3vd2tuxRESC9uymajYeOMaXLp5JZkb6/Z0c5BzIHcDX3H2tmRUCa8zsaXd/u0e5Fe5+VYBxiIj0y92547ltTBmTx7WLJyU6nIQILP25+0F3XxtbbgA2Aen5rywiSe2FLWE27KvnSxfPICsNrwogTm0GZlYOLAZW9bL5HDNbb2ZPmNnpfex/i5lVmlllOBwOMlQRSTPu0R5EZaNz+fiSskSHkzCBJwMzKwB+C3zV3Y/12LwWmOrui4A7gd/3dgx3v8fdK9y9oqSkJNB4RSS9bNhXz7q9R/mbD6bvVQEEnAzMLItoInjA3X/Xc7u7H3P3xtjy40CWmY0NMiYRke4e23CArAzj6jR7rqCnIHsTGXAvsMnd/62PMuNj5TCzpbF4aoOKSUSku0jEeWzDQT44u4SivKxEh5NQQfYmOg/4DPCmma2LrftHYAqAu98FfBL4gpl1AMeBG9zdA4xJROQda/cc4WB9C//wkTmJDiXhAksG7v4y0O8jfO7+Y+DHQcUgItKfR9cfYERmiMvSbByi3qRva4mIpLXOiPPHNw9xyZxSCkYEeZNkeFAyEJG0tKqqlprG1rQbkK4vSgYikpYe3XCQvOwMLplTmuhQkoKSgYiknfbOCH966yCXzR1HbnZGosNJCkoGIpJ2Xtlew5Hmdq5aOCHRoSQNJQMRSTuPbThIYU4mHzxNIxp0UTIQkbTS2tHJkxsPcfm88YzI1C2iLkoGIpJWXquqo6GlgysXjk90KElFyUBE0sqKrWGyM0OcM13DoHWnZCAiaWXFthqWlo9RL6IelAxEJG0cPtbClsMNnD9LVwU9KRmISNpYsa0GgAuUDN5HyUBE0saKbWHGFmQzd/zIRIeSdJQMRCQtRCLOK9trOH/mWEKhfgdUTktpkwxe2FLNJT98gSNNbYkORUQSYNOhY9Q0tnHBLD1o1pu0SQZjC0ZQVdPEnzYeSnQoIpIAai/oX5DTXk42s+fN7G0z22hmf9dLGTOzO8xsu5ltMLMlQcVz+sSRTBubz2MbDgR1ChFJYiu2hZkzvpDSkTmJDiUpBXll0AF8zd3nAWcDXzKzeT3KfBSYFXvdAvw0qGDMjKsWTuDVHbWEG1qDOo2IJKHjbZ28vusI58/UVUFfAksG7n7Q3dfGlhuATcCkHsWuAf7Lo14DRplZYMMIXrVwIhFHt4pE0szqXXW0dUS4YLbaC/oSlzYDMysHFgOremyaBOzt9n4f708YQ2b2uAJmlhbw2HrdKhJJJ11DUCwtH5PoUJJW4MnAzAqA3wJfdfdjp3iMW8ys0swqw+HwYGLhqoUTWL2rjsPHWk75OCIyvGgIihMLdBZoM8simggecPff9VJkPzC52/uy2Lr3cPd7gHsAKioqfDAxXbVwIrc/s43H3zzIX503bTCHGvbaOiK8tDXMa1W1NLV10tLeyfG2To63d9LU2kFj7NXSHmF6ST6LyopYUDaKRWVFTBmTh5n6akvyq44NQfHxJYHddEgJgSUDi35T3Atscvd/66PYI8DfmtmDwFlAvbsfDComgJmlBcwZX8hjG9IzGXR0RqjcfYQ/rDvA428epP54OzlZIQpzssjNyiA3K4OcrBAFOZmMyc+jICeTrFCILYcbuP/V3bR17ASgOD+bJVNH84Gpo6mYOprSwhwyMoyskJERMkbnZevBHkm4js4I333sbQAuOk1zHfcnyCuD84DPAG+a2brYun8EpgC4+13A48AVwHagGfirAON5x8cWTeQHT27hwNHjTByVG49TJkxVuJEXtoTZdPAYmw4dY+vhRto6IuRlZ3D5vHFcs3gS588cS1bGie8YtndG2Hq4gfV761m75whrdh/h6bcP91p2YlEO1585hU+dWcaEotT+N5bkFIk431i+gT9uOMg/XTGX08YXJjqkpGbug7rrEncVFRVeWVk5qGPsqmnioh++wD9fOZfPXTB9iCJLHu7Oq1W13LtiJ89urgaIjscyYSRzJ4xkUdkoLp5TQl724P8WqGls5Y09R6k/3k5HZ4SOiNPaEeGFLdWs2FZDyOCSOaX82eIyzp81lqLcrEGfU+RE3J1/fPgtfrN6D1/70Gy+fOmsRIeUcGa2xt0r+tyejskA4Ko7V5ARCvGHL533vm3uTk1jG3vqmpgzfiT5I4K5gGpp7+TFrWEiESczI0RWhpGblcHCslEnbOhq74zw5MZD/Gb1Ho42tzMmP5uxBSMYnZfNqp21bDxwjDH52Xzm7KncsHRyQv46313bxEOv72VZ5T5qGlvJCBlnTB7FhbNKuGxeKadPLBqyc3VGnIg7mSEb+raMDcvg2dugfh8UlcGlt8LCTw3tOWTIuDvfffRt7lu5iy9dPIOvf3hOokNKCkoGfbjrxR18/4nNXLFgPFkZITJiXyB76prZHm7kaHM7AJNG5fLD6xZxzoziQZ+zu/1Hj/OFX61hw776920bkRni3BnFXDJ3HBfNLmFUXhbtnU57Z4SGlg4eXX+A36zeQ3VDK5PH5DKzpIC6pjZqm9qobWyjbHQu/+38afzZ4knkZCW+90RHZ4Q39h7lpa1hXtoaZsP+etxhwaQi/nzpFK4+YyIFA0y47Z0Rdtc2syPcyNZDDWw+3MDWQw3srGmiIxL9fzlkkBFLCgaYgWGEDEJmhELR5a7tXXKzM5gyJi/6Ks5j+tgCzmp8htHP/g9oP/5uwaxc+NgdSghJyN35/hObufulKm4+fxr/fOVcdXSIUTLoQ/WxFm755RoaWtrpjDgdEccdJo3OZWZpATNLCiguyOb2Z7axs6aJ/3beNL7xkdOG5Mv1le01fPk3b9DeEeF7fzaf08YX0t7htHVGqD/exoptNTy7qZo9dc297m8GH5xdwo3nTOWDs0vJGGYNtXVNbTy24QC/XrWHzYcayM/O4KLTSinMyWREZogRWRlkhIyW9nd7ODW0dLCztok9tc3vfOkDTBmTx+xxhcweV0BedgYdEX/n84y4Q/Q/3KOfb2fsZ8Rj27tpbOlgd10ze+uaqWmMDmj4cvZXKAvVvL8SRZPh798K8p9JTpK78/0/bebuF6v4zNlTue2a05UIulEyGKTmtg7+9YnN3P/qbmaU5PO/rp3POdOLT+l/Mnfnrher+MGTm5lRUsDdn/kA00sK+iy7I9zEK9traOuIkJ0ZIit2K2nptDFMLc4fbNUSzt15Y+9Rfr1qD6t31tHS3klbZ4TW9ggdkQg5mRnkZEd7OOVlZ1BenM+M0nxmlBQwvaSAWaUFgd3Ca2ztYNvhBs74z2kY7/8diWD85ILXOWdGMYsmjxpQA7wEx935P09u4acv7OAvz57C/7pmvhJBD0oGQ+TlbTV8ffl6Dta3sGBSEZ+7YBpXLJgw4C+BcEMr31i+nue3hLly4QT+zycWBvZFJkPoR/Ohfu/7Vh+2Es46/u8A5GVnsHTaGM6dUcziKaM5feLIIWmcl4Fxd3741BZ+8vwO/uKsKXzvmvnq1twLJYMh1NLeye/W7ufnK6qoqmli0qhcrj5jIgsmFXH6xJF9Poj17KbDfGP5BhpbO/jHK+Zy4zlT9VfLcLFhGTz6lV7bDI7MuJbXqmpZuaOWlTtq2BFuAqJtFrNKC5k/qYjTxhe8cyUzeXQumbqCGDJHm9t46u3DPLr+ACu21fDnSyfzL9cuUCLog5JBACIR57nN1fz85Soqdx155x52YU4mc8YXUl6cT/nYfKaPzefl7TU8sGoPcyeM5N9vOIPZ49TXedgZYG+i6oYW3txXz4Z99by5P/qzpvHdEXKzMoyJo3KZWJQb/Tkqh+L8bApzsijMyaQwJ4uSwmzKRuclRcN/MqprauPJjYd4/M2DvLqjlo6IM2lULtefOZm/vXimEkE/lAwC1tLeydbDDWw8cIy39tez7XAjO2ub3jNM9i0XTudrl89mRKZ+wdNNfXM7O2oa2VHdSFVNE/uOHOfA0eMcPHqcQ8daiPTx6zehKIcpY/KYPCaP8SNzGDdyBONG5lA+Np9ZpQVpdWVZ19TGUxsP8cc3D7JyRy2dEae8OI+PLpjAFfMnMH/SyLT69zhVSgYJ0tjawa6aJkZkhpilqwHpRUdnhPrj7TS0RMeAOtbSTrihld21zeyK9Zzaf/Q41Q2tdHbLGpNG5XLZ3FIumzeOs6YVk52ZWreeOiPO+n1HeXFLmBe2htmw7yjuMLU4jysXTODKhROYN0EJ4GQpGYgMc50Rp7axlUPHWth08BjPbKpmxbYwLe0RcrJCTB2Tz+TY8xHlY/M4e3rxsLt6ONLUxkvbwjy/uZoXt4Y50tyOGZwxeRQXzS7l0rmlnD5RCWAwTpQM1OVBJMllhIzSkTmUjsxhYdkorj9zCi3tnbyyvYaVO2rZXRt9NuKV7TUcb+8EomNDffC0Ei6YVcKUMXmMystiVF42+dkZQ/aF6u60d0af1xiRGXrfcTsjztHmNo4eb8c9Wo+QgTvsqm1i2+FGth5uYPOhBt46EH0QsTg/m4vnlPLB2SVcOKuE0fnZQxKrnJiuDERShLuz/+hxVmyr4cUtYV7eXkNja8d7ymSGokOedD23kp0ZIi87g4IRmeSPyKQgJ5MMMzoikXeeem9tj9Dc1kFzW2fsFR3WvLWj8502j8yQUZCTGXtwMIOjzW3UNbX12SbSZWzBCGaPK2DptDFcfFopCyYVqRE4ILpNJJKm2jsjvLm/nnBDK/XN7RyJ/ZXe0t5JW0eE9s4IbR0Rmts6aWztoKm1g4bWjm5jZUUfcszOCJE/IpO87AzysjPJzQ5FHwiMDXceChmNsXaPhpYOWto7GZWXzdiCbIrzsxmdn42ZEYk9He7A5NG5zB5XqL/840i3iUTSVFZGiCVTRic6DBkmUqsbgoiInBIlAxERUTIQEZEAk4GZ/aeZVZtZr+P8mtlFZlZvZutir1uDikVERPoXZAPyfcCPgf/qp8wKd78qwBhERGQAArsycPeXgLqgji8iIkMn0W0G55jZejN7wsxO76uQmd1iZpVmVhkOh+MZn4hIWkhkMlgLTHX3RcCdwO/7Kuju97h7hbtXlJSUxCs+EZG0EegTyGZWDjzm7vMHUHYXUOHuvUw4+55yYWB3t1VFQP0Al8cC/R7/BLof82TL9La+57r+3nctd183mPoMpi59bRtI/H0t67M5cZwDLaPP5v2fx3CvS1/LJ1Ofqe7e91/T0YnCg3kB5cBbfWwbz7vJaCmwp+v9SZ7jnoEuA5WDrM89p1qmt/U91/X3vlsduq875foMpi6nUh99Nvps4v3ZpFJdgqpP91dgvYnM7DfARcBYM9sHfBvIAnD3u4BPAl8wsw7gOHCDx2p3kh49yeXBGMhx+irT2/qe6/p7/2gfZU7VYOrS17aBxN/f8mDos+l/Wzp+NqlUl/6Wh8SwG6huMMys0vsZqGm4SaX6pFJdILXqo7okr6GsT6J7E8XbPYkOYIilUn1SqS6QWvVRXZLXkNUnra4MRESkd+l2ZSAiIr1QMhARESUDERFRMniHmV1gZneZ2c/NbGWi4xkMMwuZ2b+Y2Z1m9tlExzNYsRFuV8Q+n4sSHc9gmVl+bHiVYT9Io5nNjX0uy83sC4mOZzDM7Foz+5mZPWRmlyc6nsEys+lmdq+ZLR9I+ZRIBn0Nl21mHzGzLWa23cy+2d8x3H2Fu38eeAy4P8h4+zMUdQGuAcqAdmBfULEOxBDVx4FGIIcE1meI6gLwD8CyYKIcuCH6vdkU+735FHBekPH2Z4jq8nt3/2vg88D1QcZ7IkNUnyp3v3nAJx2qp9cS+QIuBJbQ7WlnIAPYAUwHsoH1wDxgAdEv/O6v0m77LQMKh3NdgG8CfxPbd/lw/2yAUGy/ccADw7wuHwJuAG4Crhrun01sn6uBJ4C/GO51ie33f4ElqfDZxPYb0HdAkPMZxI27vxQbB6m7pcB2d68CMLMHgWvc/X8DvV6em9kUoN7dG4KMtz9DUZfYE99tsbedAYZ7QkP12cQcAUYEEugADNFncxGQT/SX+LiZPe7ukSDj7stQfTbu/gjwiJn9Efh1gCH3aYg+GwO+Dzzh7msDDrlfQ/x7MyApkQz6MAnY2+39PuCsE+xzM/CLwCI6dSdbl98Bd5rZBcBLQQZ2ik6qPmb2ceDDwCiiEyYlk5Oqi7v/E4CZ3QTUJCoR9ONkP5uLgI8TTdKPBxnYKTjZ35svA5cBRWY206PD5iSTk/1sioF/ARab2bdiSaNPqZwMTpq7fzvRMQwFd28mmthSgrv/jmiCSxnufl+iYxgK7v4C8EKCwxgS7n4HcEei4xgq7l5LtP1jQFKiAbkP+4HJ3d6XxdYNR6lUF0it+qRSXSC16pNKdYGA65PKyeB1YJaZTTOzbKKNdo8kOKZTlUp1gdSqTyrVBVKrPqlUFwi6PolsMR/ClvffAAd5tyvlzbH1VwBbibbA/1Oi40y3uqRafVKpLqlWn1SqS6Lqo4HqREQkpW8TiYjIACkZiIiIkoGIiCgZiIgISgYiIoKSgYiIoGQgKcLMGuN8viGZ8yI2V0O9ma0zs81m9sMB7HOtmc0bivOLdFEyEOmFmfU7bpe7nzuEp1vh7mcAi4GrzOxE8wJcS3TUU5Eho2QgKcvMZpjZn8xsjUVnSpsTW/8xM1tlZm+Y2TNmNi62/jtm9kszewX4Zez9f5rZC2ZWZWZf6XbsxtjPi2Lbl8f+sn8gNhQyZnZFbN0aM7vDzB7rL153Pw6sIzo6JWb212b2upmtN7PfmlmemZ1LdP6AH8SuJmb0VU+Rk6FkIKnsHuDL7v4B4H8A/xFb/zJwtrsvBh4EvtFtn3nAZe7+57H3c4gOn70U+LaZZfVynsXAV2P7TgfOM7Mc4G7go7Hzl5woWDMbDczi3WHHf+fuZ7r7ImAT0SEJVhIdj+br7n6Gu+/op54iA6YhrCUlmVkBcC7w/2J/qMO7E+OUAQ+Z2QSiM0bt7LbrI7G/0Lv80d1bgVYzqyY621rPqTdXu/u+2HnXAeVEp+mscveuY/8GuKWPcC8ws/VEE8Ht7n4otn6+mX2P6DwOBcCTJ1lPkQFTMpBUFQKOxu7F93Qn8G/u/khscpbvdNvW1KNsa7flTnr/nRlImf6scPerzGwa8JqZLXP3dcB9wLXuvj42Gc5FvezbXz1FBky3iSQlufsxYKeZXQfRKQ3NbFFscxHvjgP/2YBC2AJM7zZ14QknWI9dRXwf+IfYqkLgYOzW1Ke7FW2IbTtRPUUGTMlAUkWeme3r9vrvRL9Ab47dgtkIXBMr+x2it1XWADVBBBO71fRF4E+x8zQA9QPY9S7gwlgS+Z/AKuAVYHO3Mg8CX481gM+g73qKDJiGsBYJiJkVuHtjrHfRT4Bt7v6jRMcl0htdGYgE569jDcobid6aujux4Yj0TVcGIiKiKwMREVEyEBERlAxERAQlAxERQclARERQMhAREeD/AzBVpo/nOL/6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.919942</td>\n",
       "      <td>1.863471</td>\n",
       "      <td>6.446073</td>\n",
       "      <td>1:09:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/better-fine-tuned.pth')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(\"better-fine-tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"<|startoftext|>\\n Checkerboard spider \\n \"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp.cuda(), min_length=1000, max_length=1000, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftext|>\\n Checkerboard spider \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198,  6822,   263,  3526, 19230,   220,   198,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "           220,   220,   220,   220,   220,   220,   220,   220,   220,   220]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 198,  220,  220,  ...,   14, 2091,  198])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n        MuddyWater: Binder Project (Part 1)\\n\\n         marcoramilli.com/2021/05/01/muddywater-binder-project-part-1/\\n        View all posts by marcoramilli                               May 1, 2021\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        According to Lab Dookhtegan, which you migth remeber him/their from HERE, HERE and HERE, Binder is a project\\n        related to IRGC cyber espionage group build for trojenize google apps (APK). The application “trojenization” is a well-\\n        known process which takes as input a good APK and a code to inject (a RAT, for example). The system is able to\\n</td>\n",
       "      <td>\\n\\n        MuddyWater: Binder Project (Part 1)\\n\\n         marcoramilli.com/2021/05/01/muddywater-binder-project-part-1/\\n        View all posts by marcoramilli                               May 1, 2021\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        According to Lab Dookhtegan, which you migth remeber him/their from HERE, HERE and HERE, Binder is a project\\n        related to IRGC cyber espionage group build for trojenize google apps (APK). The application “trojenization” is a well-\\n        known process which takes as input a good APK and a code to inject (a RAT, for example). The system is able to\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>– Service\\n                                                               Execution\\n           Regedit   regedit     shell regedit reg             T102</td>\n",
       "      <td>– Service\\n                                                               Execution\\n           Regedit   regedit     shell regedit reg             T102 –</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even trying the GPT2 tutorial data only gets us two more words, instead of the normal several. I wonder if the massive number of `\\n`'s is confusing it, and leading it to predict only spaces and newlines. Will re-parse at reading, but if that's true, will want a clean dataset for later. \n",
    "\n",
    "I've also read a comment where adding spaces or other whitespace characters at the end of your prompt causes problems. Keep that in mind for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data like before, but replace paired \\n's with a single space. \n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            data = infile.read()\n",
    "            data.replace(\"\\n\\n\", \" \")\n",
    "            values.append(data)\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1454' class='' max='1454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1454/1454 01:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.767524</td>\n",
       "      <td>1.861074</td>\n",
       "      <td>6.430640</td>\n",
       "      <td>1:09:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp, max_length=100, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider\\n                                                                                              '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This learned lots of spaces. Huh. So perhaps replacing the \\n's with spaces just trained it to learn lots of spaces. Try again, but this time, replace any 2+ whitespace section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data like before, but replace 2+ whitespaces with  nothing\n",
    "reg_space = re.compile(r'\\s{2,}')\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            data = infile.read()\n",
    "            data = re.sub(reg_space, \" \",data)\n",
    "            values.append(data)\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1454' class='' max='1454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1454/1454 00:53<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cybereason vs. MedusaLocker Ransomware cybereason.com/blog/medusalocker-ransomware Back to Blog Cybereason Nocturnus Nov 19, 2020 Research by: Tom Fakterman and Assaf Dahan Background The MedusaLocker ransomware first emerged in September 2019, infecting and encrypting Windows machines around the world. There have been reports of MedusaLocker attacks across multiple industries, especially the healthcare industry which suffered a great deal of ransomware attacks during the COVID-19 pandemic. In order to maximize the chances of successful encryption of the files on the compromised machine, MedusaLocker restarts the machine in safe mode before execution. This method is used to avoid security tools that might not run when the computer starts in safe mode. MedusaLocker avoids encrypting executable files, most likely to avoid rendering the targeted system unusable for paying the ransom. To make it even more dangerous, MedusaLocker uses a combination of AES and RSA-2048, making the procedure of brute forcing the encryption practically impossible.</td>\n",
       "      <td>bereason vs. MedusaLocker Ransomware cybereason.com/blog/medusalocker-ransomware Back to Blog Cybereason Nocturnus Nov 19, 2020 Research by: Tom Fakterman and Assaf Dahan Background The MedusaLocker ransomware first emerged in September 2019, infecting and encrypting Windows machines around the world. There have been reports of MedusaLocker attacks across multiple industries, especially the healthcare industry which suffered a great deal of ransomware attacks during the COVID-19 pandemic. In order to maximize the chances of successful encryption of the files on the compromised machine, MedusaLocker restarts the machine in safe mode before execution. This method is used to avoid security tools that might not run when the computer starts in safe mode. MedusaLocker avoids encrypting executable files, most likely to avoid rendering the targeted system unusable for paying the ransom. To make it even more dangerous, MedusaLocker uses a combination of AES and RSA-2048, making the procedure of brute forcing the encryption practically impossible. Recently,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T attack and how they respond to an APT? Most organisations focus on Our analysis shows that a majority of the procedures of preventing an external attacker from threat actors can be detected by monitoring process getting access to internal resources, and file operations. These detection methods are the but few take measures to detect most effective ones, to detect the attack patterns used an attacker once he/she has access within targeted attacks. This, too, tallies with what to the internal network. Costin Raiu said. The following illustration of the top ten detection methods underlines this once again: Process Monitoring 149 File monitoring 86 Process command-line parameters 82 API monitoring 36 Process use of network 34 Windows Registry 34 Packet capture 31 Authentication logs 28 Netﬂow/Enclave netﬂow 23 Binary ﬁle metadata 17 0 20 40 60 80 100 120 140 160 kcattA eht gnitcudnoC Detection methods for process activities identify</td>\n",
       "      <td>attack and how they respond to an APT? Most organisations focus on Our analysis shows that a majority of the procedures of preventing an external attacker from threat actors can be detected by monitoring process getting access to internal resources, and file operations. These detection methods are the but few take measures to detect most effective ones, to detect the attack patterns used an attacker once he/she has access within targeted attacks. This, too, tallies with what to the internal network. Costin Raiu said. The following illustration of the top ten detection methods underlines this once again: Process Monitoring 149 File monitoring 86 Process command-line parameters 82 API monitoring 36 Process use of network 34 Windows Registry 34 Packet capture 31 Authentication logs 28 Netﬂow/Enclave netﬂow 23 Binary ﬁle metadata 17 0 20 40 60 80 100 120 140 160 kcattA eht gnitcudnoC Detection methods for process activities identify</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.599804</td>\n",
       "      <td>3.285584</td>\n",
       "      <td>26.724592</td>\n",
       "      <td>31:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to note that this took approximately half the time to train that the full-witespace one did. There was apparently a *lot* of whitespace in the raw files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-content/uploads/2018/10/checkerboard- spider.com/wp-'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ummm....okaaaay. It learned that it was supposed to put the actor name in a wordpress blog url (hah), but nothing else. sigh. 'k. Perhaps we need to remove the blog urls also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Operation Overtrap Targets Japanese Online Banking Users Via Bottle Exploit Kit and Brand-New Cinobi Banking Trojan Technical Brief By Jaromir Horejsi and Joseph C. Chen (Threat Researchers) We recently discovered a new campaign that we dubbed “Operation Overtrap” for the numerous ways it can infect or trap victims with its payload. The campaign mainly targets online users of various Japanese banks by stealing their banking credentials using a three-pronged attack. Based on our telemetry, Operation Overtrap has been active since April 2019 and has been solely targeting online banking user...\n",
       "1     Trend Micro About TrendLabs Security Intelligence Blog Search: Home Categories Home » Bad Sites » New Andariel Reconnaissance Tactics Hint At Next Targets Featured Stories New Andariel Reconnaissance Tactics Hint At Next Targets systemd Vulnerability Leads to Denial of Service on Linux Posted on: July 16, 2018 at 8:10 am Posted in: Bad Sites Author: Joseph C Chen (Fraud Researcher) qkG Filecoder: Self-Replicating, Document- In cooperation with IssueMakersLab of South Korea Encrypting Ransomware Reconnaissance plays a vital role in criminal operations, and Mitigating CVE-2017-5689, an Inte...\n",
       "2     9/10/2018 Leviathan: Espionage actor spearphishes maritime and defense targets Leviathan: Espionage actor spearphishes maritime and defense targets proofpoint.com/us/threat‑insight/post/leviathan‑espionage‑actor‑spearphishes‑maritime‑and‑defense‑targets October 17, 2017 Overview Proofpoint researchers are tracking an espionage actor targeting organizations and high‑value targets in defense and government. Active since at least 2014, this actor has long‑standing interest in maritime industries, naval defense contractors, and associated research institutions in the United States and Western...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing more stuff\n",
    "\n",
    "Okay, I re-ran the Prefect data generation job, this time having it do the following:\n",
    " 1. remove code snippets like before.\n",
    " 2. replace all white-space-like characters with a single space (so \"\\n\\n\\n\\t\\n  \" would change to \" \")\n",
    " 3. replace all urls and word-press-like strings with \" \"\n",
    " \n",
    "My hope is that this removes the things that the previous runs were grabbing as common factors, and teaches it legitimate TI jargon & style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start from the top\n",
    "base_dir = Path(\"/home/g-clef/local_ml_data_copy/ti-reports/671bc9ae-0e33-45a6-bb56-c13457c5a510\")\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            values.append(infile.read())\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]\n",
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1462' class='' max='1462' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1462/1462 00:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6081 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.575670</td>\n",
       "      <td>3.614600</td>\n",
       "      <td>37.136478</td>\n",
       "      <td>11:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Side-note: this trained even faster than the earlier ones (11 minutes), which implies that it was having problems with the URLs as well in previous training runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.com/blog/2018/05/checkerboard-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-soph'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's a bit on the nose. \n",
    "\n",
    "I don't like that it's still looking like a URL, but the fact that all it's saying is \"sophisticated\" is fucking hilarious.\n",
    "\n",
    "Does it do that every time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.com/blog/2018/05/checkerboard-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-sophisticated-soph'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yup. Okay, that's really funny. \n",
    "\n",
    "I apparently missed some URLs. Let's try one last prefect run to remove even more URL-like things (I didn't chop out urls that were missing the `http` at the beginning. Apparently that was a mistake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, have run re-run the prefect job, removing all things that look even vaguely like URLs. Those are in the run labeled `d7b917db-7989-468c-87e2-dc0c63b90e2c`. So let's re-do the above with that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start from the top\n",
    "base_dir = Path(\"/home/g-clef/local_ml_data_copy/ti-reports/d7b917db-7989-468c-87e2-dc0c63b90e2c\")\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            values.append(infile.read())\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]\n",
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1463' class='' max='1463' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1463/1463 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (26837 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]\n",
    "\n",
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]\n",
    "\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.133877</td>\n",
       "      <td>3.633630</td>\n",
       "      <td>37.849957</td>\n",
       "      <td>09:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider. This is the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have seen this type of malware being used in the wild, and it’s the first time we have'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better. It's still repeating things over and over, but it's at least an English sentence. Now, I'm looking at that error above that talks about `Token indices sequence length is longer than the specified maximum sequence length for this model (26837 > 1024). Running this sequence through the model will result in indexing errors`. I'm wondering if I need to cut the files up into <= 1024-word sequences. Let's try that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start from the top\n",
    "base_dir = Path(\"/home/g-clef/local_ml_data_copy/ti-reports/d7b917db-7989-468c-87e2-dc0c63b90e2c\")\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            data = infile.read()\n",
    "            words = data.split()\n",
    "            accum = list()\n",
    "            for word in words:\n",
    "                accum.append(word)\n",
    "                if len(accum) == 1023:\n",
    "                    values.append(\" \".join(accum))\n",
    "                    accum = list()\n",
    "            if accum:\n",
    "                values.append(\" \".join(accum))\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]\n",
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2573' class='' max='2573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2573/2573 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]\n",
    "\n",
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]\n",
    "\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No error log. Promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.345060</td>\n",
       "      <td>3.434101</td>\n",
       "      <td>31.003523</td>\n",
       "      <td>09:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.exe, which is used to download and execute a payload from the C&C server. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. The first and second sentence work fine. After that it just loops again. But this is definite progress: it's making english-like sentences, they match the format of what we'd expect. It's just that it's still getting caught in these crazy loops. A GPT2 bug mentioned changing the \"temperature\" to fix this. Let's try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.exe, which is used to download and execute a payload from the C&C server. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the C&C server using the HTTP GET request. The payload is then sent to the'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1000)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't work, but apparently there are a few other things I can set. *IMPORTANTLY*, there's a `no_repeat_ngram_size` variable, to keep it from getting stuck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.exe, which is used to download and execute a payload from the C&C server. The payload is then sent to a remote server, where it is decrypted and sent back to the attacker. Once the payload has been downloaded and executed, it will be executed in a new thread. This is the first time we have seen this type of malware being used in the wild. It is interesting to note that in this case, the malware does not contain any malicious code at all. Instead, we see that the attackers are using this malware as a lure to lure victims into clicking on the malicious link. Figure 1: Screenshot of a malicious downloader Figure 2: A screenshot of an infected web page Figure 3: An infected webpage Figure 4: Infected web pages Figure 5: The infected page is shown in Figure 6 Figure 7: Figure 8: Malicious PDF document Figure 9: PDF file containing malicious content Figure 10: Attacker’s web browser Figure 11: Spearphishing email with malicious attachment Figure 12: Attachment containing malware Figure 13: HTML document containing a link to an embedded malicious file Figure 14: Embedded malicious document in PDF format Figure 15: Link to embedded executable Figure 16: Exploitation method used by attackers to infect victims Figure 17: Targeted spearphish email sent from a compromised web server Figure 18: Credential harvesting technique used for phishing attacks Figure 19: Command and control (C2) communication between attackers and C2 servers Figure 20: HTTP POST request for a command to be sent Figure 21: User-Agent (HTTP/1.1) response Figure 22: Content-Length of the HTTP request Figure 23: Data sent by the command Figure 24: Encrypted data received Figure 25: MD5 hash of encoded data Figure 26: SHA-1 of decoded data (SHA-256) Figure 27: Hash of encrypted data in encrypted form Figure 28: XOR-encrypted data with a key of 0x5A Figure 29: Hexadecimal key for the decryption key Figure 30: AES-128-CBC algorithm for encryption Figure 31: RC4-encryption for AES Figure 32: Decryption of AES data Table 1 shows a list of commands that can be performed on infected systems Figure 33: Commands that are executed by a malware sample Figure 34: Indicators of Compromise (IoC)\\x00\\x00 Figure 35: Information about the infected system Figure 36: List of infected computers Figure 37: System information about infected machines Figure 38: Network traffic from infected hosts Figure 39: IP address of compromised computer Figure 40: Internet Protocol Protocol (IP) addresses Figure 41: IPv4 Address for infected computer Table 2 shows the IP addresses and port numbers for each infected machine Figure 43: TCP port number for TCP ports Figure 44: UDP port for UDP ports Table 3 shows an example of how a TCP connection is made Figure 45: Example of TCP connections Figure 46: Examples of UDP connections Table 4 shows how an attacker can use the TCP protocol to communicate with the victim Figure 47: How attackers can send and receive commands Figure 48: Sending and receiving commands Table 5 shows some examples of command-and-control (P2P) communications Figure 49: Communication between a client and a server Table 6 shows what commands are sent and received by infected clients Figure 50: Control flow between the server and the client Figure 51: Server-side command flow Figure 52: Client-server communication Figure 53: Connection between infected servers Table 7 shows HTTP requests for commands and HTTP responses Figure 54: Accept-Encoding (encoded) requests Figure 55: Request for HTTP GET Figure 56: Response for POST Figure 57: Uploading and downloading files Figure 58: Downloading files Table 9 shows commands for downloading and executing a file Table 10 shows various files and directories Table 11 shows different types of files, such as executables and executable archives Table 12 shows files with different extensions Table 13 shows file names Table 14 shows directory names for files that have different extension Table 15 shows directories for directories that contain different file types Table 16 shows folders for folders that do not have the same file type Table 17 shows folder names of folders Table 18 shows specific files for which a particular extension is not present Table 19 shows all files on a given folder Table 20 lists the directories of directories on which the file is installed Table 21 lists files in which an extension exists Table 22 lists all folders on an archive Table 23 lists a folder named “C:\\\\Documents and Settings\\\\All Users\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Explorer\\\\” Table 24 lists folders with specific extensions TABLE 25 lists directories with unique extension TABLE 26 lists file paths Table 27 lists directory paths for different files TABLE 28 lists folder paths TABLE 29 lists specific file path names TABLE 30 lists an executable path Table 31 lists executable paths of different versions Table 32 lists installed files of various versions TABLE 33 lists various file extensions of each version Table 34 lists known file'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5, early_stopping=True, no_repeat_ngram_size=2)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. This is quite good. It gets caught it a bit of a loop at the end with \"figure\" and \"table\" entries, but still. It's the best I've seen so far. Fantastic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this makes me wonder if my efforts to remove the URLs and the like earlier were unnecessary. Perhaps what I really needed to do at the beginning was split up the input files at 1024 words, and set the `no_repeat_ngrams_size` variable on the data without all the filtering, i.e. the first attempt. Let's go back to the very first dataset, and try it.\n",
    "\n",
    "First, though, let's save this model, because it's working, and that's fantastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/filtered_working.pth')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(\"filtered_working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/home/g-clef/local_ml_data_copy/ti-reports/1655302d-a401-4d87-a223-dbb06648bb8f\")\n",
    "values = list()\n",
    "for entry in os.listdir(base_dir):\n",
    "    if entry.endswith(\".txt\"):\n",
    "        with open(os.path.join(base_dir, entry)) as infile:\n",
    "            data = infile.read()\n",
    "            words = data.split()\n",
    "            accum = list()\n",
    "            for word in words:\n",
    "                accum.append(word)\n",
    "                if len(accum) == 1023:\n",
    "                    values.append(\" \".join(accum))\n",
    "                    accum = list()\n",
    "            if accum:\n",
    "                values.append(\" \".join(accum))\n",
    "df = pd.DataFrame(data=values, columns=[\"text\"])\n",
    "train, valid = train_test_split(df, test_size=0.1, random_state=42)\n",
    "all_texts = np.concatenate([train['text'].values, valid['text'].values])\n",
    "splits = [range_of(train), list(range(len(train), len(all_texts)))]\n",
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6624' class='' max='6624' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6624/6624 00:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]\n",
    "\n",
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]\n",
    "\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.527252</td>\n",
       "      <td>3.153177</td>\n",
       "      <td>23.410316</td>\n",
       "      <td>32:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider.com/wp-includes/pomo/checker.php https://www.trendmicro. com/en_us/research/20/l/sidewinder-apt-group-continues-to-target-government-and-military-institutions-in-the-middle-east/ 1/12 2/4/2020 Sidewinders: APT group continues to target government and military institutions in the Middle East | TrendLabs Security Intelligence Blog Figure 1. Screenshot of the malicious document. Figure 2. A screenshot of a decoy document with a link to a malicious PDF file. The document has the following structure: Figure 3. An example of an email sent to an individual with the subject “Your email address will not be published.” Figure 4. Email sent by the individual to the email. This email was sent from the same address as the one used to send the spear-phishing email (Figure 5). Figure 5. Spearphished email from a victim with an attached PDF attachment. In this case, the attachment was a Word document, which contained an attachment that contained malicious code that would download and execute an executable file from hxxp://192.168.0.1:8080/download.exe Figure 6. Code that downloads and executes the downloaded executable. It is worth noting that this executable is not a legitimate executable, but rather a downloader that is downloaded and executed by a remote attacker. We believe that the attackers behind this campaign are using a custom toolkit that allows them to execute arbitrary code on the victim’s machine, as seen in Figure 7 and Figure 8. Conclusion The threat actor behind the campaign has been active for at least two years, and it is likely that they continue to be active as long as they are able to maintain access to victim networks. However, we do not have enough evidence to conclusively attribute this activity to any specific actor or group of threat actors. Based on our telemetry, it seems unlikely that any particular actor is responsible for this attack, or that there is any direct connection between this actor and the group behind it. Further research is needed to determine who is behind these attacks and how they operate. Indicators of Compromise (IoCs) The following IoCs can be used as indicators of compromise in order to identify potential victims of interest: • C&C server IP address • IP addresses used for command and control (C2) • Domain names used in spear phishing emails • Malicious domains used by attackers to deliver malicious payloads • Email addresses and URLs that redirect victims to malicious domains • URL short URL paths that lead to legitimate websites (e.g., www.google[.]com, google.co.uk, etc.) • MD5 hashes of malicious files • SHA-256 hash of files that have been uploaded to VirusTotal (SHA-1 hashes) We have also identified a number of other domains that are associated with this group. These domains are linked to other groups that we believe are related to this threat group, such as DarkHotel and DarkComet. While we have not found any evidence of direct links between these groups, there are some indications that these domains may be linked with other threat groups. For more information about the domains, please contact intelreports@kaspersky.COM. © 2020 All rights reserved to ClearSky Cyber Security Ltd. All other trademarks and service marks are the property of their respective owners. Trend Micro, Incorporated. and/or its affiliates are trademarks or registered trademarks of TrendMicro, a registered trademark or service mark of its respective companies in this document or its content. Any use of this information is at any time without the benefit of legal advice based on its accuracy or use is subject to standard copyright rules at the end user. Use of information contained on this page constitutes acceptance for use in whole or in part in reliance on information provided herein and without providing a means of payment. You agree that access is provided to you, its use and that you agree to use it for personal, non-commercial use or copying of any content or material for any purpose, express or implied, including without limitation, without limiting the right to print, electronic, photocopying, recording, transmission, distribution, copying, display, copy, presentation, reproduction or any other use without obtaining permission in writing or by any means other than by electronic means. Information contained herein is for general information and educational purposes only and may not reflect the most current situation. Copyright © 2019 All Rights Reserved. | Privacy Shield | Legal Notices | Terms of Use | Disclaimer | Contact Us | Site Map | Blog | About the Threat Research Center ofﬁcial Blog �ash \\uf0ec \\uf06c\\x00\\x00 \\uf001\\uf003\\uf0c0\\uf08d \\uf10d\\uf10e \\uf16a\\uf14c�'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, max_length=1000, num_beams=5, temperature=1.5, early_stopping=True, no_repeat_ngram_size=2)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm....not *bad*, per se, but interestingly, not as good as the earlier one. I like that it's generating urls, and it's entertaining that it's included (and *learned*) the legal disclaimers and copyright boilerplate. That's entertaining. \n",
    "\n",
    "Let's see if we can do better, though. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the blog post that pointed me to `no_repeat_ngram_size` (https://huggingface.co/blog/how-to-generate ) also mentioned a few other parameters that you could use to clean up generated code. It's explaining what's happening here:\n",
    "    * `num_beams`: a \"beam\" is a set of words in a tree of possible words following a given word. Using beams, the algorithm picks the *beam* with the highest probability, rather than the individual next word. That makes some sense, since it's more likely to make coherent sentences. It does, however, have the repeating problem I've seen here. \n",
    "    * `Temperature` is a measure of randomness that gets added to the sampling, but apparently doesn't help much in beaming, since it'll just keep picking the same high-probability beams. \n",
    "    * `early_stopping` allows the algorithm to stop before the max or min length if it's used up all its possible outputs, which helps avoid repetition.\n",
    "    * `no_repeat_ngram_size` is a way to stop it from repeating words. It means that the algorithm keeps ngrams that have already been used in the text generation, and ensures they're never used again in that generation pass. That's great for breaking out of repetition, but it means that names, for example, will never be used again, which is a problem. (In the blog example, `New York` would trigger a 2-gram, and so would only ever be used once in a text generation, which may not be what you want if you want something about New York.\n",
    "    \n",
    "There's another method of generating text that blog post talks about that may be better than beaming, specifically \"sampling\". Basically, in sampling the algorithm is picking the next word based on the statistical probability of it following the previous words. A bit like a <insert name of the thing I used to generate spam blocking text>. That works fairly well, but has the bad habit of picking weird words, since it's just doing a statistical decision. (so every 1 out of 100, for example, it'll pick a really rare word.) \n",
    "\n",
    "One way to fix that is to use \"top-k\" sampling. This is the idea that when you sample, you limit the next words that can be chosen to the top \"k\" next words. This avoids accidentally choosing really weird next words. The blog post mentions that this works, but doesn't take into account that some words will have very few words that statistically follow them (\"quest\") and some will have *Many* (\"the\"). Top \"K\" doesn't take that into account, it just hard-limits the words that can follow any word to a fixed number. \n",
    "    \n",
    "Instead, the post talks about using \"top-p\" sampling. In top-p sampling, you pick the next word from a pool of words whose probability totals up to \"p\". When you do that, the algorithm picks the *minimum* number of words that will fill that probability, and then picks from those words for hte next word in the sequence. That seems to work best in his demonstrations, so let's try that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider - a new open-source toolset with a command-line interface that can be found in the open-source Firefox spyware webshells, see the list of “Spyware” here. Most of the tools are not available on the open-source web server. The webshells are built on top of the popular webshells, such as the “Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail.Mail'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, \n",
    "                             max_length=1000, \n",
    "                             temperature=0.7, \n",
    "                             do_sample=True, \n",
    "                             top_p=0.92, \n",
    "                             top_k=0)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gah. What the fuck is that?\n",
    "\n",
    "I left out one thing, the blog post also mentioned setting `num_return_sequences` to allow it to pick more than one possible response from its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n checkerboard spider: https://blog.talosintelligence.com/2020/10/cve-2018-0158-analysis-of-apt-group-targets-minority-organizations/ 6/10 10/12/2020 Cisco Talos Intelligence Group - Comprehensive Threat Intelligence: APT Group Targets Minority Organizations | WeLiveSecurity The APT group was active from January 2019 to March 2020, but was not observed in any of the samples analyzed. The threat actor has been active since at least 2018, and it is believed that the threat actor is still active at this time. However, this group is not a new threat actor. In June 2019, Talos detected the threat actor in a campaign against a U.S.-based video game company that targeted a U.S.-based video game company. The actor used a new remote access trojan (RAT) to perform reconnaissance on the company’s video game system. This RAT is a backdoor that allows the actor to steal video game files. The actor leveraged a previously unknown tool called nmap, which was developed by a local administrator at the company, to download and execute additional malicious code. The actor used the nmap command to download and execute additional malicious code, as well as a legitimate Java file called Inject.jar. Inject.jar is a legitimate Java file that is used to download additional malicious code from the infected system. Inject.jar contains code that is used to download additional malicious code from the infected system. The malicious code downloaded from the infected system has been analyzed in detail in the next section. The malware is designed to evade detection by Windows Defender products and is likely developed for use in targeted attacks. In this attack, the actor used an exploit kit that was compiled using the same exploit kit as the one described in the previous section. The malware is written in C++. The actor has used the following obfuscation techniques to hide its malicious code in the memory: • The code obfuscated the embedded code in the code (the obfuscation technique described in this section) and uses a hardcoded string to store the embedded code within the malicious code to evade detection • The obfuscation technique used by the code obfuscate the embedded code in the code (the string obfuscation technique described in this section) The code is designed to hide its malicious code in the memory to avoid detection by Microsoft Visual Studio applications • The obfuscated code is used to hide the obfuscation technique that is used to hide the embedded code in the memory in the memory of the memory of the infected system This is a technique that is used to avoid detection by Microsoft Visual Studio applications • The obfuscation technique is used to hide the embedded code in the memory of the infected system (the code obfuscated by the string obfuscation technique described in this section) • The code is obfuscated using the same technique that is used to hide the embedded code in the memory of the infected system (the code obfuscated by the string obfuscation technique described in this section) The code is obfuscated using the same technique that is used to hide the embedded code in the memory of the infected system • The code obfuscation technique is used to obfuscate the embedded code in the memory of the infected system (the code obfuscated by the string obfuscation technique described in this section) The code has an internal name of “hxxp://”, which is an internal name of the Windows Command and Control server (e.g. “winmgt.com”). This information is not encrypted, so it is used to hide the malicious code in the memory of the infected system. The code is then executed using the malware to encrypt the embedded code and then execute it using a randomly generated key to encrypt the embedded code. The malware performs the following actions: 1. It checks the system name of the system. 2. It retrieves the name of the current process (e.g. “winmgt.com”) and checks if the system name is “winmgt.com”. 3. It checks if the process name of the system is “winmgt.com” and if it is “winmgt.com”. 4. It tries to determine if the file “winmgt.com” is running in the system. It then checks if the file “winmgt.com” is running in the system. The malware uses the following command to get the system name: “winmgt.com”: winmgt.com.exe (c:\\\\windows\\\\system32\\\\winmgt.com.exe) 5. It tries to set the file “winmgt.com” to “winmgt.com.exe” and then starts the “winmgt.com”'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n checkerboard spider\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "preds = learn.model.generate(inp, \n",
    "                             max_length=1000, \n",
    "                             temperature=0.7, \n",
    "                             do_sample=True, \n",
    "                             top_p=0.92, \n",
    "                             num_return_sequences=3,\n",
    "                             top_k=0)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. It's clearly memorized a few things, like URLs and TI company names, but otherwise this is *really* good. \n",
    "\n",
    "Let's save this model, since I'm really happy with these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/full-working.pth')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(\"full-working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
